"""
ELASTICSEARCH OCR RETRIEVAL SYSTEM - with FUZZY SEARCH
Compatible with Elasticsearch 8.11.0

T√≠nh nƒÉng:
‚úÖ Keyword Search (BM25)
‚úÖ Fuzzy Search (cho ph√©p g√µ sai)
‚úÖ Interactive Search Loop
‚úÖ Incremental Indexing
"""

import os
import json
from elasticsearch import Elasticsearch
from sentence_transformers import SentenceTransformer
from tqdm import tqdm
from typing import List, Dict
import warnings
import hashlib
warnings.filterwarnings('ignore')


# ========================== HELPER FUNCTIONS ==========================

def get_file_hash(filepath: str) -> str:
    """T√≠nh hash c·ªßa file ƒë·ªÉ ph√°t hi·ªán thay ƒë·ªïi"""
    hash_md5 = hashlib.md5()
    try:
        with open(filepath, "rb") as f:
            for chunk in iter(lambda: f.read(4096), b""):
                hash_md5.update(chunk)
        return hash_md5.hexdigest()
    except Exception:
        return ""


def extract_video_and_frame_from_path(image_path: str) -> tuple:
    """
    Extract video name v√† frame number t·ª´ ƒë∆∞·ªùng d·∫´n
    
    Example:
    D:\\...\\K11\\K11_V001\\000002.webp
    ‚Üí video_name: K11_V001
    ‚Üí frame_idx: 2
    """
    try:
        # L·∫•y filename: 000002.webp
        filename = os.path.basename(image_path)
        # L·∫•y frame number: 2
        frame_idx = int(os.path.splitext(filename)[0])
        
        # L·∫•y video name: K11_V001
        parent_dir = os.path.dirname(image_path)
        video_name = os.path.basename(parent_dir)
        
        return video_name, frame_idx
    except:
        return "unknown", 0


# ========================== MAIN CLASS ==========================

class OCRRetrievalES:
    """
    OCR Retrieval System using Elasticsearch
    
    Features:
    - Keyword search (BM25) with FUZZY option
    - Incremental indexing
    """
    
    def __init__(
        self,
        ocr_json_dir: str,
        host: str = "http://localhost:9200",
        index_name: str = "ocr_index_new",
        load_data: bool = False,
        force_reindex: bool = False,
        index_tracker_file: str = ".indexed_ocr_files.json"
    ):
        """
        Kh·ªüi t·∫°o OCR Retrieval System
        
        Args:
            ocr_json_dir: Th∆∞ m·ª•c ch·ª©a c√°c file JSON OCR
            host: Elasticsearch host URL
            index_name: T√™n index trong Elasticsearch
            load_data: C√≥ load d·ªØ li·ªáu v√†o ES kh√¥ng
            force_reindex: True = index l·∫°i t·∫•t c·∫£
            index_tracker_file: File JSON l∆∞u danh s√°ch file ƒë√£ index
        """
        self.ocr_json_dir = ocr_json_dir
        self.index_name = index_name
        self.force_reindex = force_reindex
        self.index_tracker_file = index_tracker_file

        print("="*80)
        print("üöÄ KH·ªûI ƒê·ªòNG OCR RETRIEVAL SYSTEM")
        print("="*80)
        
        # Load danh s√°ch file ƒë√£ index
        self.indexed_files = self._load_indexed_files()
        
        # K·∫øt n·ªëi Elasticsearch
        self._connect_elasticsearch(host)
        

        
        # T·∫°o index
        self._setup_index()
        
        # Index d·ªØ li·ªáu
        if load_data:
            self._index_data()

    def _load_indexed_files(self) -> Dict[str, str]:
        """Load danh s√°ch file ƒë√£ index t·ª´ file JSON"""
        if self.force_reindex:
            print("\n‚ö†Ô∏è  Force reindex enabled - s·∫Ω index l·∫°i t·∫•t c·∫£ file")
            return {}
        
        if os.path.exists(self.index_tracker_file):
            try:
                with open(self.index_tracker_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                print(f"\nüìã ƒê√£ load th√¥ng tin {len(data)} file ƒë√£ index")
                return data
            except Exception as e:
                print(f"\n‚ö†Ô∏è  Kh√¥ng th·ªÉ ƒë·ªçc {self.index_tracker_file}: {e}")
                return {}
        else:
            print(f"\nüìã File tracker ch∆∞a t·ªìn t·∫°i - s·∫Ω t·∫°o m·ªõi")
            return {}

    def _save_indexed_files(self):
        """L∆∞u danh s√°ch file ƒë√£ index v√†o file JSON"""
        try:
            with open(self.index_tracker_file, 'w', encoding='utf-8') as f:
                json.dump(self.indexed_files, f, ensure_ascii=False, indent=2)
            print(f"\nüíæ ƒê√£ l∆∞u th√¥ng tin {len(self.indexed_files)} file")
        except Exception as e:
            print(f"\n‚ö†Ô∏è  Kh√¥ng th·ªÉ l∆∞u tracker: {e}")

    def _should_index_file(self, filepath: str) -> bool:
        """Ki·ªÉm tra xem file c√≥ c·∫ßn index kh√¥ng"""
        if self.force_reindex:
            return True
        
        current_hash = get_file_hash(filepath)
        
        if filepath in self.indexed_files:
            stored_hash = self.indexed_files[filepath]
            if stored_hash == current_hash:
                return False
        
        return True

    def _connect_elasticsearch(self, host: str):
        """K·∫øt n·ªëi t·ªõi Elasticsearch"""
        print(f"\nüîå ƒêang k·∫øt n·ªëi t·ªõi {host}...")
        
        try:
            from elasticsearch import __version__ as es_version
            print(f"   Phi√™n b·∫£n client: {es_version}")
            
            self.es = Elasticsearch(
                hosts=[host],
                verify_certs=False,
                ssl_show_warn=False,
                request_timeout=30,
                max_retries=3,
                retry_on_timeout=True
            )
            
            info = self.es.info()
            print(f"‚úÖ K·∫øt n·ªëi th√†nh c√¥ng!")
            print(f"   - Cluster: {info['cluster_name']}")
            print(f"   - Version: {info['version']['number']}")
            
        except Exception as e:
            print(f"\n‚ùå L·ªñI K·∫æT N·ªêI: {e}")
            raise ConnectionError("Kh√¥ng th·ªÉ k·∫øt n·ªëi t·ªõi Elasticsearch!")

    def _setup_index(self):
        """T·∫°o index n·∫øu ch∆∞a t·ªìn t·∫°i"""
        print(f"\nüîß Ki·ªÉm tra index '{self.index_name}'...")
        
        try:
            if self.es.indices.exists(index=self.index_name):
                print(f"‚ÑπÔ∏è  Index ƒë√£ t·ªìn t·∫°i")
                return
            
            print(f"üî® T·∫°o index m·ªõi...")
            mapping = {
                "mappings": {
                    "properties": {
                        "text": {"type": "text"},
                        "image_path": {"type": "keyword"},
                        "filename": {"type": "keyword"},
                        "video_name": {"type": "keyword"},
                        "frame_idx": {"type": "integer"},
                        "source_file": {"type": "keyword"}
                        }
                    }
                }
            
            self.es.indices.create(index=self.index_name, body=mapping)
            print("‚úÖ Index ƒë√£ ƒë∆∞·ª£c t·∫°o!")
            
        except Exception as e:
            print(f"‚ö†Ô∏è  L·ªói khi t·∫°o index: {e}")
            raise

    def _index_data(self):
        """ƒê·ªçc v√† index d·ªØ li·ªáu t·ª´ c√°c file JSON OCR"""
        print("\n" + "="*80)
        print("üìÇ B·∫ÆT ƒê·∫¶U INDEX D·ªÆ LI·ªÜU OCR (INCREMENTAL)")
        print("="*80)
        print(f"Th∆∞ m·ª•c: {self.ocr_json_dir}\n")
        
        # ƒê·∫øm s·ªë file
        all_files = []
        for root, _, files in os.walk(self.ocr_json_dir):
            for file in files:
                if file.endswith(".json"):
                    all_files.append(os.path.join(root, file))
        
        print(f"üìä T·ªïng s·ªë file JSON: {len(all_files)}")
        print(f"üìã S·ªë file ƒë√£ index tr∆∞·ªõc ƒë√≥: {len(self.indexed_files)}")
        
        # L·ªçc file c·∫ßn index
        files_to_index = [f for f in all_files if self._should_index_file(f)]
        files_skipped = len(all_files) - len(files_to_index)
        
        print(f"üÜï File c·∫ßn index: {len(files_to_index)}")
        print(f"‚è≠Ô∏è  File b·ªè qua (ƒë√£ index): {files_skipped}")
        
        if len(files_to_index) == 0:
            print("\n‚úÖ Kh√¥ng c√≥ file m·ªõi - B·ªè qua indexing")
            return
        
        print()
        
        count = 0
        indexed_count = 0
        
        for full_path in files_to_index:
            try:
                with open(full_path, "r", encoding="utf-8") as f:
                    data = json.load(f)
                
                file_display = os.path.basename(full_path)
                print(f"üìÑ {file_display} ({len(data)} entries)")
                
                # Index t·ª´ng entry
                for image_path, ocr_data in tqdm(data.items(), desc=f"  Indexing", leave=False):
                    # ocr_data format: ["filename.webp", "text content"]
                    if not isinstance(ocr_data, list) or len(ocr_data) < 2:
                        continue
                    
                    filename = ocr_data[0]
                    text = ocr_data[1].strip()
                    
                    if not text:
                        continue
                    
                    # Extract video name v√† frame number
                    video_name, frame_idx = extract_video_and_frame_from_path(image_path)
                    
                    doc = {
                        "text": text,
                        "image_path": image_path,
                        "filename": filename,
                        "video_name": video_name,
                        "frame_idx": frame_idx,
                        "source_file": full_path
                    }

                self.es.index(index=self.index_name, document=doc)
                # C·∫≠p nh·∫≠t hash c·ªßa file v√†o tracker
                self.indexed_files[full_path] = get_file_hash(full_path)
                indexed_count += 1
                
                print(f"   ‚úÖ ƒê√£ index xong\n")
                
            except Exception as e:
                print(f"   ‚ö†Ô∏è  L·ªói: {e}\n")
        
        # L∆∞u danh s√°ch file ƒë√£ index
        self._save_indexed_files()

    def search(self, query: str, top_k, use_fuzzy: bool = False) -> Dict:
        results = {}

        # 1. Keyword Search (BM25) v·ªõi Fuzzy option
        if use_fuzzy:
            keyword_query = {
                "size": top_k,
                "query": {
                    "match": {
                        "text": {
                            "query": query,
                            "fuzziness": "AUTO",
                            "prefix_length": 1,
                            "max_expansions": 50
                        }
                    }
                }
            }
        else:
            keyword_query = {
                "size": top_k,
                "query": {"match": {"text": query}}
            }
        
        resp = self.es.search(index=self.index_name, body=keyword_query)
        results["keyword"] = [hit["_source"] for hit in resp["hits"]["hits"]]

        return results

    def display_results(self, results: Dict, top_k):
        mode_results = results.get("keyword", [])  # ‚úÖ L·∫•y ra ngo√†i loop
    
        if not mode_results:
            print("‚ùå Kh√¥ng t√¨m th·∫•y k·∫øt qu·∫£")
            return []  # ‚úÖ Return empty list
    
            # Gi·ªõi h·∫°n s·ªë k·∫øt qu·∫£ n·∫øu c·∫ßn
        display_list = mode_results[:top_k] if top_k else mode_results
    
    # Return list paths
        paths = [r.get('image_path', 'N/A') for r in display_list]
        return paths

    def reset_index_tracker(self):
        """X√≥a file tracker - d√πng khi mu·ªën index l·∫°i t·ª´ ƒë·∫ßu"""
        if os.path.exists(self.index_tracker_file):
            os.remove(self.index_tracker_file)
            print(f"üóëÔ∏è  ƒê√£ x√≥a {self.index_tracker_file}")
            self.indexed_files = {}
        else:
            print(f"‚ÑπÔ∏è  File {self.index_tracker_file} kh√¥ng t·ªìn t·∫°i")


# ========================== INTERACTIVE SEARCH ==========================
def interactive_ocr_search(query, top_k, OCR_JSON_DIR, index_name,retrieval):
    retrieval = retrieval
    
    # ‚úÖ B·ªé while True, ch·ªâ search 1 l·∫ßn
    try:
        results = retrieval.search(query, top_k=top_k, use_fuzzy=True)
        return retrieval.display_results(results, top_k)
    except Exception as e:
        print(f"\n‚ùå L·ªói: {e}")



# ========================== MAIN PROGRAM ==========================

if __name__ == "__main__":
    # C·∫•u h√¨nh ƒë∆∞·ªùng d·∫´n
    OCR_JSON_DIR = r"D:\Workplace\OCR\Output"  # ‚ö†Ô∏è THAY ƒê·ªîI ƒê∆Ø·ªúNG D·∫™N N√ÄY
    
    # ============ CH·∫æ ƒê·ªò 1: INDEX D·ªÆ LI·ªÜU ============
    retrieval = OCRRetrievalES(
        ocr_json_dir=OCR_JSON_DIR,
        host="http://localhost:9200",
        index_name="ocr_index_new",
        load_data=True,  # True = index d·ªØ li·ªáu
        force_reindex=True
    )
    
    # # ============ CH·∫æ ƒê·ªò 2: CH·ªà T√åM KI·∫æM ============
    
    # print (interactive_ocr_search("tr·∫£ n·ª£", 500, OCR_JSON_DIR, "ocr_index_main"))